{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .rendered_html code { \n",
       "    padding: 2px 4px;\n",
       "    color: #c7254e;\n",
       "    background-color: #f9f2f4;\n",
       "    border-radius: 4px;\n",
       "} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "# %pylab osx\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from scipy.misc import imresize\n",
    "from skimage.transform import resize\n",
    "# Some additional libraries which we'll use just\n",
    "# to produce some visualizations of our training\n",
    "from libs.utils import montage\n",
    "from libs import gif\n",
    "import IPython.display as ipyd\n",
    "plt.style.use('ggplot')\n",
    "import struct\n",
    "import re\n",
    "from PIL import Image\n",
    "import gzip\n",
    "import codecs\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Bit of formatting because I don't like the default inline code style:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code { \n",
    "    padding: 2px 4px;\n",
    "    color: #c7254e;\n",
    "    background-color: #f9f2f4;\n",
    "    border-radius: 4px;\n",
    "} </style>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_images(files, input_dir):\n",
    "    for i in range(0, len(files)):\n",
    "        print (i)\n",
    "        img1 = plt.imread(os.path.join(input_dir, files[i]))\n",
    "        img1 = (img1 * 255).round().astype(np.uint8)\n",
    "        img1 = imresize(img1, (64,64))\n",
    "        for j in range(i+1 , len(files)):\n",
    "            if (files[j][:4] == files[i][:4]):\n",
    "                name = \"match\"+str(files[i][:10]) + \"_\"+ str(files[j][:10]) + \".png\"\n",
    "                img2 = plt.imread(os.path.join(input_dir, files[j]))\n",
    "                img2 = (img2 * 255).round().astype(np.uint8)\n",
    "                img2 = imresize(img2, (64,64))\n",
    "                #img = img1 & img2\n",
    "                img = np.vstack( (img1,img2))\n",
    "                plt.imsave(os.path.join('/Users/nikhilshekhar/deep_learning_working_directory/data/', name),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def non_match_images(files, input_dir):\n",
    "    for i in range(1, 1569):\n",
    "        if(i < 10):\n",
    "            key = \"000\" + str(i)\n",
    "        elif (i < 100):\n",
    "            key = \"00\" + str(i)\n",
    "        elif (i <1000):\n",
    "            key = \"0\" + str(i)\n",
    "        else :\n",
    "            key = str(i)\n",
    "        shortlisted_file_names = [ filename for filename in files if filename[:4] == key]\n",
    "        print(i)\n",
    "        if shortlisted_file_names:\n",
    "            shortlisted = list(set(files) - set(shortlisted_file_names))\n",
    "            for j in range(0,54):\n",
    "                img1_key = random.choice(shortlisted_file_names)\n",
    "                #print img1_key\n",
    "                img1 = plt.imread(os.path.join(input_dir, img1_key))\n",
    "                img1 = (img1 * 255).round().astype(np.uint8)\n",
    "                img1 = imresize(img1, (64,64))\n",
    "                img2_key = random.choice(shortlisted)\n",
    "                shortlisted = list(set(shortlisted) - set(img2_key))\n",
    "                img2 = plt.imread(os.path.join(input_dir, img2_key))\n",
    "                name = \"mis_match\" + str(img1_key[:10]) + \"_\" + str(img2_key[:10]) + \".png\"\n",
    "                img2 = (img2 * 255).round().astype(np.uint8)\n",
    "                img2 = imresize(img2, (64,64))\n",
    "                img = np.vstack( (img1,img2)) \n",
    "                plt.imsave(os.path.join('/Users/nikhilshekhar/deep_learning_working_directory/data/', name),img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = '/Users/nikhilshekhar/deep_learning_working_directory/images/'\n",
    "files = [ input_file for input_file in os.listdir(input_dir) if '.png' in input_file]\n",
    "\n",
    "# match_images(files, input_dir)\n",
    "# non_match_images(files, input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_images(input_dir, output_filename, ext='.png'):\n",
    "    # Ensure the input directory has a trailing slash\n",
    "    if input_dir[-1] != '/':\n",
    "        input_dir += '/'\n",
    "\n",
    "    fs = [input_dir + x for x in np.sort(os.listdir(input_dir)) if ext in x]\n",
    "    num_imgs = len(fs)\n",
    "    output_file = open(output_filename, \"wb\")\n",
    "    print(num_imgs)\n",
    "    # Write items in the header\n",
    "    # MNIST uses 2051 as a magic number in the header, so following convention here\n",
    "    output_file.write(struct.pack('>i', 2051))       # Magic Number for train/test images\n",
    "    output_file.write(struct.pack('>i', num_imgs))   # Number of images\n",
    "\n",
    "    # Load the first image to get dimensions\n",
    "    im = np.asarray(Image.open(fs[0]).convert('L'), dtype=np.uint32)\n",
    "    r,c = im.shape\n",
    "\n",
    "    # Write the rest of the header\n",
    "    output_file.write(struct.pack('>i', r))          # Number of rows in 1 image\n",
    "    output_file.write(struct.pack('>i', c))          # Number of columns in 1 image\n",
    "\n",
    "    # For each image, record the pixel values in the binary file\n",
    "    for img in range(10): #num_imgs\n",
    "        im = np.asarray(Image.open(fs[img]).convert('L'), dtype=np.uint32)\n",
    "        for i in range(im.shape[0]):\n",
    "            for j in range(im.shape[1]):\n",
    "                output_file.write(struct.pack('>B', im[i,j]))\n",
    "\n",
    "    # Close the file\n",
    "    output_file.close()\n",
    "    \n",
    "#     with open(output_filename, encoding=utf-8) as f_in:\n",
    "#         print(enc, f.read(500))\n",
    "#     f_in = open(output_filename)\n",
    "    f_in = codecs.open(output_filename,\"r\",encoding=\"utf-8\")\n",
    "    f_out = gzip.open(output_filename + '.gz', 'wb')\n",
    "    f_out.writelines(f_in)\n",
    "#     f_out.writelines(f_in)\n",
    "    f_out.close()\n",
    "    f_in.close()\n",
    "    os.remove(output_filename)\n",
    "    \n",
    "\n",
    "#############################encoding labels the same way as images#################################################################################################################\n",
    "\n",
    "def encode_labels(input_dir, output_filename, ext='.png' ):\n",
    "\n",
    "    if input_dir[-1] != '/':\n",
    "        input_dir += '/'\n",
    "\n",
    "    fs = [input_dir + x for x in np.sort(os.listdir(input_dir)) if ext in x]\n",
    "    num_imgs = len(fs)\n",
    "    output_file = open(output_filename, \"wb\")\n",
    "\n",
    "    print (num_imgs)\n",
    "    # Write items in the header\n",
    "    # MNIST uses 2051 as a magic number in the header, so following convention here\n",
    "    output_file.write(struct.pack('>i', 2049))  # Magic Number for train/test images\n",
    "    output_file.write(struct.pack('>i', num_imgs))  # Number of images\n",
    "\n",
    "    # Load the first image to get dimensions\n",
    "    print(fs[0])\n",
    "    im = np.asarray(Image.open(fs[0]).convert('L'), dtype=np.uint32)\n",
    "\n",
    "    # For each image, record the pixel values in the binary file\n",
    "    count = 0\n",
    "    for img in range(num_imgs):\n",
    "        count+=1\n",
    "        print(count)\n",
    "        #print fs[img]\n",
    "        if re.match(input_dir+'match.*', fs[img]):\n",
    "            label = 1\n",
    "        elif re.match(input_dir + 'mis_match.*' , fs[img]):\n",
    "            label=0\n",
    "        label = np.uint32(label)\n",
    "        print(label)\n",
    "        output_file.write(struct.pack('>B', label))\n",
    "\n",
    "    # Close the file\n",
    "    output_file.close()\n",
    "\n",
    "#     f_in = open(output_filename)\n",
    "#     with open(output_filename, encoding=utf-8) as f_in:\n",
    "#         print(enc, f.read(500))\n",
    "    f_in = codecs.open(output_filename,\"r\",encoding=\"utf-8\")\n",
    "    f_out = gzip.open(output_filename + '.gz', 'wb')\n",
    "    f_out.writelines(f_in)\n",
    "    f_out.close()\n",
    "    f_in.close()\n",
    "    os.remove(output_filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167211\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8d in position 6: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-04dfa963c30d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencode_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/nikhilshekhar/deep_learning_working_directory/data/'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/nikhilshekhar/deep_learning_working_directory/data/training-images-and-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mencode_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/nikhilshekhar/deep_learning_working_directory/data/'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/nikhilshekhar/deep_learning_working_directory/data/training-labels-and-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#encode('/home/sanjana/Handwritten_and_preprocessed_v2/testing_data/' , 'testing-images-and-ubyte',label=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#encode('/home/sanjana/Handwritten_and_preprocessed_v2/testing_data/' , 'testing-labels-and-ubyte',label = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-d93d01ffd12d>\u001b[0m in \u001b[0;36mencode_images\u001b[0;34m(input_dir, output_filename, ext)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mf_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mf_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#     f_out.writelines(f_in)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mf_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nikhilshekhar/anaconda/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nikhilshekhar/anaconda/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nikhilshekhar/anaconda/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size, keepends)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# If size is given, we call read() only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirstline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# If we're at a \"\\r\" read one extra character (which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nikhilshekhar/anaconda/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size, chars, firstline)\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 \u001b[0mnewchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecodedbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfirstline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8d in position 6: invalid start byte"
     ]
    }
   ],
   "source": [
    "encode_images('/Users/nikhilshekhar/deep_learning_working_directory/data/' , '/Users/nikhilshekhar/deep_learning_working_directory/data/training-images-and-ubyte')\n",
    "encode_labels('/Users/nikhilshekhar/deep_learning_working_directory/data/' , '/Users/nikhilshekhar/deep_learning_working_directory/data/training-labels-and-ubyte')\n",
    "#encode('/home/sanjana/Handwritten_and_preprocessed_v2/testing_data/' , 'testing-images-and-ubyte',label=False)\n",
    "#encode('/home/sanjana/Handwritten_and_preprocessed_v2/testing_data/' , 'testing-labels-and-ubyte',label = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
